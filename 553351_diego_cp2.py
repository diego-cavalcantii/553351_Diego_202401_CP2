# -*- coding: utf-8 -*-
"""553351_Diego_CP2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Y5NSE7xLKH-eklCtqQFrsUlAkSqeqVkE
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

from google.colab import drive
drive.mount('/content/drive')

file_path = "/content/drive/MyDrive/Csvs/billboard.csv"

df = pd.read_csv(file_path)

# Origem
print("Origem: Dados coletados do site Kaggle.")

# Nome
print("Nome: Top 100 Songs on Billboard")

# Tamanho
print(f"Tamanho: {df.memory_usage().sum()} bytes")

# Quantidade de Registros
print(f"Quantidade de Registros: {len(df)}")

# Linhas x Colunas
print(f"Linhas x Colunas: {df.shape}")

# Dados Faltantes
print("Dados Faltantes:")
print(df.isnull().sum())

#  Exclusão de variáveis
df.drop(columns=['Rank'], inplace=True)  # Excluindo a coluna 'Rank'

# Carregar os dados

# Calcular a matriz de correlação
correlation_matrix = df[numeric_cols].corr()

# Visualizar a matriz de correlação
print("Matriz de Correlação:")
print(correlation_matrix)

# Selecionar apenas as colunas numéricas do DataFrame
numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns

# Calcular a matriz de correlação apenas com as colunas numéricas
correlation_matrix = df[numeric_cols].corr()

# Plotar a matriz de correlação
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title("Matriz de Correlação")
plt.show()

# Converter variáveis categóricas em variáveis dummy
X = pd.get_dummies(X)

# Dividir os dados em conjunto de treino e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Inicializar e treinar o modelo de Regressão Logística
model = LogisticRegression()
model.fit(X_train, y_train)

# Fazer previsões no conjunto de teste
y_pred = model.predict(X_test)

# Calcular a matriz de confusão
cm = confusion_matrix(y_test, y_pred)

print(cm)

# Plotar a matriz de confusão
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', cbar=False)
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Confusion Matrix')
plt.show()

# Apresentar o classification report
print(classification_report(y_test, y_pred))

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix
from joblib import dump
import streamlit as st
from joblib import load

# Carregar os dados
file_path = "/content/drive/MyDrive/Csvs/billboard.csv"
df = pd.read_csv(file_path)

# Excluir a coluna 'Rank'
df.drop(columns=['Rank'], inplace=True)

# Converter variáveis categóricas em variáveis dummy
df = pd.get_dummies(df)

# Dividir os dados em conjunto de treino e teste
X = df.drop(columns=['Peak Position'])
y = df['Peak Position']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Inicializar e treinar o modelo de Regressão Logística
model = LogisticRegression()
model.fit(X_train, y_train)

# Fazer previsões no conjunto de teste
y_pred = model.predict(X_test)

# Calcular a matriz de confusão
cm = confusion_matrix(y_test, y_pred)

# Salvar o modelo treinado
dump(model, 'model.joblib')

# Aplicação Streamlit
st.title('Previsão de Posição de Pico na Billboard')

# Carregar o modelo treinado
model = load('model.joblib')

# Perguntar ao usuário pelos atributos
sepal_length = st.slider('Comprimento da Sépala:', min_value=0.0, max_value=10.0, value=5.0)
sepal_width = st.slider('Largura da Sépala:', min_value=0.0, max_value=10.0, value=3.0)
petal_length = st.slider('Comprimento da Pétala:', min_value=0.0, max_value=10.0, value=1.0)
petal_width = st.slider('Largura da Pétala:', min_value=0.0, max_value=10.0, value=0.5)



# Exibir a previsão
st.write(f'A posição de pico prevista é: {prediction[0]}')

from joblib import dump

# Treinar o modelo
# model.fit(X_train, y_train)

# Supondo que seu modelo esteja treinado, agora você pode salvá-lo
dump(model, 'model.joblib')

pip install streamlit

# Supondo que X_test contenha os dados de teste com apenas 4 features
# Você precisa garantir que tenha 248 features para corresponder ao modelo treinado
# Você pode preencher o restante das features com zeros, por exemplo

import numpy as np

# Criar uma matriz com zeros para as features adicionais
additional_features = np.zeros((X_test.shape[0], 248 - X_test.shape[1]))

# Concatenar os dados de teste originais com as features adicionais
X_test_extended = np.concatenate((X_test, additional_features), axis=1)

# Fazer a previsão usando o modelo com os dados de teste estendidos
prediction = model.predict(X_test_extended)

# Exibir as previsões
print("Previsões:")
print(prediction)